{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4a807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import json\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import hashlib\n",
    "import hmac\n",
    "import base64\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from pandas.io.json import json_normalize\n",
    "from prophet import Prophet\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 한글 글씨체 설정\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "pd.set_option('display.max_columns', 250)\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.width', 100)\n",
    "#소수점 아래 5자리까지 표시\n",
    "pd.options.display.float_format = '{: .5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30a2c6",
   "metadata": {},
   "source": [
    "# 네이버 API 함수 (API키 숨기기 추가 필요)\n",
    "- https://wooiljeong.github.io/python/naver_datalab_open_api/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6924c6",
   "metadata": {},
   "source": [
    "# API 인증 정보 설정(yaml)\n",
    "import yaml\n",
    "with open('./config.yaml', encoding='UTF-8') as f:\n",
    "    _cfg = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc16e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어 선택\n",
    "from config import *\n",
    "_cfg = config\n",
    "\n",
    "# 자체 검색어\n",
    "keyword_list = _cfg['Keyword']['User_list']\n",
    "# 식신 카테고리\n",
    "keyword_list = _cfg['Keyword']['Siksin']\n",
    "# 식품첨가물용어집(식품안전나라 용어사전)\n",
    "keyword_list = _cfg['Keyword']['Food_Safety_Dict']\n",
    "# 네이버 식품 카테고리 인기검색어 top500\n",
    "keyword_list = _cfg['Keyword']['Naver_Food_Rank']\n",
    "# 요식업 브랜드명\n",
    "keyword_list = _cfg['Keyword']['Food_Brand']\n",
    "# 식품안전정보 검색어(식품안전정보원 글로벌 정보부)\n",
    "keyword_list = _cfg['Keyword']['Food_Safety_Issue']\n",
    "# 식품안전나라 검색어 기록(22/09/13 기준)\n",
    "keyword_list = _cfg['Keyword']['Food_Safety_Search']\n",
    "\n",
    "\n",
    "# 검색어 통합\n",
    "keyword_list = sum(_cfg['Keyword'].values(), [])\n",
    "# 중복제거\n",
    "keyword_unique = []\n",
    "[keyword_unique.append(x) for x in keyword_list if x not in keyword_unique].clear() #None 반복 출력을 막기 위한 clear\n",
    "\n",
    "#특수문자 제거\n",
    "keyword_list = sum([re.findall('[가-힣a-z0-9]+', x) for x in keyword_unique], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51adb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 식품안전나라 용어사전 원본파일\n",
    "#df_dict = pd.read_csv('src/dict_json.csv') \n",
    "#dict_list = list(df_dict['단어'])\n",
    "#keyword_list = dict_list\n",
    "#필터링 이후 파일(find_error_list() 함수 실행 후 저장) -653/813\n",
    "df_dict = pd.read_csv('data/input_keyword/Food_info_dict.csv', encoding='cp949', header=None)\n",
    "keyword_list = list(df_dict.T[0])\n",
    "\n",
    "\n",
    "\n",
    "# 네이버 식품카테고리 인기검색어 500\n",
    "#방법1\n",
    "with open('data/input_keyword/1015_1115_식품검색어500.txt','r',encoding='utf-8') as f:\n",
    "    a = f.readlines()\n",
    "#특수문자 제거\n",
    "keyword_list = sum([re.findall('[가-힣a-z0-9]+', x) for x in a], [])\n",
    "#방법2\n",
    "keyword_list = list(pd.read_table('data/input_keyword/1015_1115_식품검색어500.txt', header=None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "44ff14e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1662004970.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [127]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class Parameter():\n",
    "    def __init__(self):\n",
    "        self.num = random.randrange(4)\n",
    "        # 검색어 지정\n",
    "        #keyword = keyword_list##################\n",
    "        \"\"\"\n",
    "        # API 인증 정보 설정(yaml)\n",
    "        import yaml\n",
    "        with open('./config.yaml', encoding='UTF-8') as f:\n",
    "            _cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \"\"\"\n",
    "        self.client_id = _cfg['NAVER_TREND'][f'client_id{self.num}']\n",
    "        self.client_secret = _cfg['NAVER_TREND'][f'client_secret{self.num}']\n",
    "    # 광고API 인증정보\n",
    "    BASE_URL = _cfg['NAVER_AD']['BASE_URL']\n",
    "    API_KEY = _cfg['NAVER_AD']['API_KEY']\n",
    "    SECRET_KEY = _cfg['NAVER_AD']['SECRET_KEY']\n",
    "    CUSTOMER_ID = _cfg['NAVER_AD']['CUSTOMER_ID']\n",
    "    \n",
    "    # 요청 파라미터 설정\n",
    "    \"\"\"\n",
    "    요청 결과 반환\n",
    "    timeUnit - 'date', 'week', 'month'\n",
    "    device - None, 'pc', 'mo'\n",
    "    ages = [], ['1' ~ '11']\n",
    "    gender = None, 'm', 'f'\n",
    "    \"\"\"\n",
    "    startDate = str(datetime(2016, 1, 1).strftime('%Y-%m-%d')) #네이버API 최초 제공일자\n",
    "    endDate = str(datetime.now().date().strftime('%Y-%m-%d')) #오늘\n",
    "    timeUnit = 'date'\n",
    "    device = ''\n",
    "    ages = []\n",
    "    gender = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "33d2769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaverDataLabOpenAPI():\n",
    "    \"\"\"\n",
    "    네이버 데이터랩 오픈 API 컨트롤러 클래스\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        인증키 설정 및 검색어 그룹 초기화\n",
    "        \"\"\"\n",
    "        parameter_ = Parameter()\n",
    "        self.client_id = parameter_.client_id\n",
    "        self.client_secret = parameter_.client_secret\n",
    "        self.keywordGroups = []\n",
    "        self.url = \"https://openapi.naver.com/v1/datalab/search\"\n",
    "\n",
    "    def add_keyword_groups(self, group_dict):\n",
    "        \"\"\"\n",
    "        검색어 그룹 추가\n",
    "        \"\"\"\n",
    "\n",
    "        keyword_gorup = {\n",
    "            'groupName': group_dict['groupName'],\n",
    "            'keywords': group_dict['keywords']\n",
    "        }\n",
    "        \n",
    "        self.keywordGroups.append(keyword_gorup)\n",
    "        #print(f\">>> Num of keywordGroups: {len(self.keywordGroups)}\")\n",
    "        \n",
    "    def get_data(self):\n",
    "        # Request body\n",
    "        body = json.dumps({\n",
    "            \"startDate\": Parameter.startDate,\n",
    "            \"endDate\": Parameter.endDate,\n",
    "            \"timeUnit\": Parameter.timeUnit,\n",
    "            \"keywordGroups\": self.keywordGroups,\n",
    "            \"device\": Parameter.device,\n",
    "            \"ages\": Parameter.ages,\n",
    "            \"gender\": Parameter.gender\n",
    "        }, ensure_ascii=False)\n",
    "        \n",
    "        # Results\n",
    "        request = urllib.request.Request(self.url)\n",
    "        request.add_header(\"X-Naver-Client-Id\",self.client_id)\n",
    "        request.add_header(\"X-Naver-Client-Secret\",self.client_secret)\n",
    "        request.add_header(\"Content-Type\",\"application/json\")\n",
    "        response = urllib.request.urlopen(request, data=body.encode(\"utf-8\"))\n",
    "        rescode = response.getcode()\n",
    "        if(rescode==200):\n",
    "            # Json Result\n",
    "            result = json.loads(response.read())\n",
    "            \n",
    "            df = pd.DataFrame(result['results'][0]['data'])[['period']]\n",
    "            for i in range(len(self.keywordGroups)):\n",
    "                tmp = pd.DataFrame(result['results'][i]['data'])\n",
    "                tmp = tmp.rename(columns={'ratio': result['results'][i]['title']})\n",
    "                df = pd.merge(df, tmp, how='left', on=['period'])\n",
    "            self.df = df.rename(columns={'period': '날짜'})\n",
    "            self.df['날짜'] = pd.to_datetime(self.df['날짜'])\n",
    "            \n",
    "        else:\n",
    "            print(\"Error Code:\" + rescode)\n",
    "            \n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2b360196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번 실행\n",
    "# 5개 이하 검색어만 허용\n",
    "def one_search(keyword):\n",
    "    if type(keyword) == str:\n",
    "        naver = NaverDataLabOpenAPI()\n",
    "        naver.add_keyword_groups({'groupName': keyword, 'keywords': [keyword]})\n",
    "    elif type(keyword) == list: # 2개 이상 검색어 입력시 리스트로\n",
    "        naver = NaverDataLabOpenAPI()\n",
    "        for i in keyword: # 최대5개\n",
    "            naver.add_keyword_groups({'groupName': i, 'keywords': [i]})\n",
    "    df = naver.get_data()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "85ec5874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>식품안전나라</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>0.00140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>0.04181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>0.03240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>0.03881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>0.59137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>0.70961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2023-02-04</td>\n",
       "      <td>0.11103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>2023-02-05</td>\n",
       "      <td>0.10343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>0.58277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             날짜   식품안전나라\n",
       "0    2016-10-25  0.00100\n",
       "1    2016-12-09  0.00140\n",
       "2    2017-01-23  0.04181\n",
       "3    2017-01-24  0.03240\n",
       "4    2017-01-25  0.03881\n",
       "...         ...      ...\n",
       "2203 2023-02-02  0.59137\n",
       "2204 2023-02-03  0.70961\n",
       "2205 2023-02-04  0.11103\n",
       "2206 2023-02-05  0.10343\n",
       "2207 2023-02-06  0.58277\n",
       "\n",
       "[2208 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = one_search('식품안전나라')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6619d3",
   "metadata": {},
   "source": [
    "# 네이버스토어 순위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba7cdb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_rank(keyword):\n",
    "    # API 인증 정보 설정\n",
    "    client_id = Parameter.client_id\n",
    "    client_secret = Parameter.client_secret\n",
    "    \n",
    "    encText = urllib.parse.quote(keyword) \n",
    "    shop_url = \"https://openapi.naver.com/v1/search/shop?query=\" + encText + \"&amp;display=100&amp;start=1\" #100순위\n",
    "    request = urllib.request.Request(shop_url) \n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        json_str = response_body.decode('utf-8')\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "    json_object  = json.loads(json_str) #json 변환\n",
    "    #json_object\n",
    "    #df = pd.DataFrame(json_object['items'])\n",
    "\n",
    "    #제목, 최저가, 몰이름, 브랜드, 대분류, 중분류, 소분류, 세부\n",
    "    #df.loc[ :, ['title', 'lprice', 'mallName', 'brand', 'productId','category1', 'category2', 'category3', 'category4']] \n",
    "\n",
    "    # 쇼핑 검색결과\n",
    "    n = 1\n",
    "    for i in range(0, len(json_object['items'])) :\n",
    "        title = json_object['items'][i]['title']\n",
    "        title = title.replace('&lt;b&gt;', \"\")\n",
    "        title = title.replace('&lt;/b&gt;', \"\")\n",
    "        mallName = json_object['items'][i]['mallName']\n",
    "        print(str(n) + ',' + title +',' + mallName)\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98e0c83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Parameter' has no attribute 'client_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Project\\PJ1\\Naver_Search_Amount\\NAVER_trend.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Project/PJ1/Naver_Search_Amount/NAVER_trend.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#1번 키로만 가능\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Project/PJ1/Naver_Search_Amount/NAVER_trend.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m store_rank(\u001b[39m'\u001b[39;49m\u001b[39m노트북\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\user\\Project\\PJ1\\Naver_Search_Amount\\NAVER_trend.ipynb Cell 12\u001b[0m in \u001b[0;36mstore_rank\u001b[1;34m(keyword)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Project/PJ1/Naver_Search_Amount/NAVER_trend.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstore_rank\u001b[39m(keyword):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Project/PJ1/Naver_Search_Amount/NAVER_trend.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# API 인증 정보 설정\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Project/PJ1/Naver_Search_Amount/NAVER_trend.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     client_id \u001b[39m=\u001b[39m Parameter\u001b[39m.\u001b[39;49mclient_id\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Project/PJ1/Naver_Search_Amount/NAVER_trend.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     client_secret \u001b[39m=\u001b[39m Parameter\u001b[39m.\u001b[39mclient_secret\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Project/PJ1/Naver_Search_Amount/NAVER_trend.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     encText \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39mquote(keyword) \n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Parameter' has no attribute 'client_id'"
     ]
    }
   ],
   "source": [
    "#1번 키로만 가능\n",
    "store_rank('노트북')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847370b4",
   "metadata": {},
   "source": [
    "# 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efbd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_trend(df):\n",
    "    \"\"\"\n",
    "    일 별 검색어 트렌드 그래프 출력\n",
    "    \"\"\"\n",
    "    colList = df.columns[1:]\n",
    "    n_col = len(colList)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.title('일 별 검색어 트렌드', size=20, weight='bold')\n",
    "    for i in range(n_col):\n",
    "        sns.lineplot(x=df['날짜'], y=df[colList[i]], label=colList[i])\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_monthly_trend(df):\n",
    "    \"\"\"\n",
    "    월 별 검색어 트렌드 그래프 출력\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df_0 = df.groupby(by=[df['날짜'].dt.year, df['날짜'].dt.month]).mean().droplevel(0).reset_index().rename(columns={'날짜': '월'})\n",
    "    df_1 = df.groupby(by=[df['날짜'].dt.year, df['날짜'].dt.month]).mean().droplevel(1).reset_index().rename(columns={'날짜': '년도'})\n",
    "\n",
    "    df = pd.merge(df_1[['년도']], df_0, how='left', left_index=True, right_index=True)\n",
    "    df['날짜'] = pd.to_datetime(df[['년도','월']].assign(일=1).rename(columns={\"년도\": \"year\", \"월\":'month','일':'day'}))\n",
    "\n",
    "    colList = df.columns.drop(['날짜','년도','월'])\n",
    "    n_col = len(colList)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.title('월 별 검색어 트렌드', size=20, weight='bold')\n",
    "    for i in range(n_col):\n",
    "        sns.lineplot(x=df['날짜'], y=df[colList[i]], label=colList[i])\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_pred_trend(df, days): #Prophet 예측 모델\n",
    "    \"\"\"\n",
    "    검색어 시계열 트렌드 예측 그래프 출력\n",
    "    days: 예측일수\n",
    "    \"\"\"\n",
    "    colList = df.columns[1:]\n",
    "    n_col = len(colList)\n",
    "\n",
    "    fig_list = []\n",
    "    for i in range(n_col):\n",
    "\n",
    "        globals()[f\"df_{str(i)}\"] = df[['날짜', f'{colList[i]}']]\n",
    "        globals()[f\"df_{str(i)}\"] = globals()[f\"df_{str(i)}\"].rename(columns={'날짜': 'ds', f'{colList[i]}': 'y'})\n",
    "\n",
    "        m = Prophet()\n",
    "        m.fit(globals()[f\"df_{str(i)}\"])\n",
    "\n",
    "        future = m.make_future_dataframe(periods=days)\n",
    "        forecast = m.predict(future)\n",
    "        forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "\n",
    "        globals()[f\"fig_{str(i)}\"] = m.plot(forecast, figsize=(12,6))\n",
    "        plt.title(colList[i], size=20, weight='bold')\n",
    "\n",
    "        fig_list.append(globals()[f\"fig_{str(i)}\"])\n",
    "\n",
    "    return fig_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6accc717",
   "metadata": {},
   "source": [
    "# 최대값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비율 값이 가장 작은 검색어 찾기 (사용은 하지않음)\n",
    "def min_key(data):\n",
    "    min_value = data.min()[1:].values.min()\n",
    "    data_ = data[data.values == min_value]\n",
    "    for i in data_.columns:\n",
    "        try:\n",
    "            if (data_[i].values == min_value):\n",
    "                return i\n",
    "        # 최소값이 같은 검색어가 있을 경우 오류 발생\n",
    "        except:\n",
    "            if (data_[i].values[:1] == min_value):\n",
    "                return i\n",
    "            \n",
    "# 비율 값이 가장 큰(100) 검색어 찾기 \n",
    "def max_key(data):\n",
    "    data_ = data[data.values == 100]\n",
    "    for i in data_.columns:\n",
    "        try:\n",
    "            if (data_[i].values == 100):\n",
    "                return i\n",
    "        except:\n",
    "            if (data_[i].values[:1] == 100):\n",
    "                return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준열인 100값 찾기 (오류가 발생한다면, 모든 값에 대해 검색값을 갖는 검색어가 없다는 의미)\n",
    "def find_max_key(keyword): #input 형태는 반드시 리스트\n",
    "    # 리스트에 중복값 있을 경우 삭제 (순서가 바뀔 수 있지만, 시간복잡도를 고려해 max값만 찾는 경우에는 set연산 사용)\n",
    "    keyword = [x.replace(' ','') for x in keyword] #공백제거(한달치 검색량에 안 잡힘)\n",
    "    my_set = set(keyword) #집합set으로 변환\n",
    "    keyword_unique = list(my_set) #list로 변환\n",
    "    keyword = keyword_unique.copy()\n",
    "    \n",
    "    #검색결과가 너무 적은 경우는 오류처리 하는 것으로 보임\n",
    "    error_list = []\n",
    "    \n",
    "    #결측치가 있는 경우 다른 검색어에 대해서도 결측값이 생기는 점 확인. 이를 대비하기 위한 결측치 리스트 생성\n",
    "    single_list = []\n",
    "    \n",
    "        \n",
    "    #한번 미리 실행\n",
    "    ############################################ 처음 검색하는 단어,제외되고 처음이 된 단어가 검색결과가 없는 데이터면 오류발생\n",
    "    while True:\n",
    "        try:\n",
    "            df = one_search(keyword[0])\n",
    "            break\n",
    "        except:\n",
    "            error_list.append(keyword[0])\n",
    "            keyword.remove(keyword[0])\n",
    "            \n",
    "    while len(df) != (datetime.now() - datetime(2016, 1, 1)).days: #첫 검색어는 모든 날짜에 값이 존재하는 검색어가 와야 함\n",
    "        single_list.append(keyword[0])\n",
    "        keyword.remove(keyword[0])\n",
    "        while True:\n",
    "            try:\n",
    "                df = one_search(keyword[0])\n",
    "                break\n",
    "            except:\n",
    "                error_list.append(keyword[0])\n",
    "                keyword.remove(keyword[0])\n",
    "        \n",
    "    # 검색어 리스트가 4의 배수가 아니면 4의 배수로 만들기 (검색오류 대비)\n",
    "    while (len(keyword)%4-1) != 0:\n",
    "        keyword.append('임시')\n",
    "        \n",
    "    df_total = df.copy()\n",
    "\n",
    "    # 검색어 리스트 값을 키워드로 지정\n",
    "    for i in tqdm(range(1, len(keyword)-3, 4)):\n",
    "        key1 = keyword[i]\n",
    "        key2 = keyword[i+1]\n",
    "        key3 = keyword[i+2]\n",
    "        key4 = keyword[i+3]\n",
    "\n",
    "        max_key_ = max_key(df) # 최대값 비교를 위한 복사\n",
    "        \n",
    "        # 데이터 프레임 정의 (one_search([max_key_,key1,key2,key3,key4]로 바꾸면 안 되나??)\n",
    "        keyword_group_set = {\n",
    "            'keyword_group_1': {'groupName': max_key_, 'keywords': [max_key_]},\n",
    "            'keyword_group_2': {'groupName': key1, 'keywords': [key1]},\n",
    "            'keyword_group_3': {'groupName': key2, 'keywords': [key2]},\n",
    "            'keyword_group_4': {'groupName': key3, 'keywords': [key3]},\n",
    "            'keyword_group_5': {'groupName': key4, 'keywords': [key4]}\n",
    "        }\n",
    "        \n",
    "        naver = NaverDataLabOpenAPI()\n",
    "\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_1'])\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_2'])\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_3'])\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_4'])\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_5'])\n",
    "        \n",
    "        try:\n",
    "            df = naver.get_data()\n",
    "\n",
    "            # 결측치 있는 최대값후보 single_list에 넣기\n",
    "            while df[max_key(df)].isnull().any(): #결측값이 하나라도 있으면 max_key가 되면 안 된다.\n",
    "                single_list.append(max_key(df))\n",
    "                temp_list = [key1, key2, key3, key4]\n",
    "                temp_list.remove(max_key(df))\n",
    "                while (len(temp_list) != 3):\n",
    "                    temp_list.append('임시')\n",
    "\n",
    "                naver = NaverDataLabOpenAPI()\n",
    "                naver.add_keyword_groups({'groupName': max_key_, 'keywords': [max_key_]})\n",
    "                naver.add_keyword_groups({'groupName': temp_list[0], 'keywords': [temp_list[0]]})\n",
    "                naver.add_keyword_groups({'groupName': temp_list[1], 'keywords': [temp_list[1]]})\n",
    "                naver.add_keyword_groups({'groupName': temp_list[2], 'keywords': [temp_list[2]]})\n",
    "                df = naver.get_data()\n",
    "\n",
    "                \n",
    "                # 이 부분 꼭 필요한지 모르겠음 실험해보기~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            if max_key_ == max_key(df):\n",
    "                df_total = pd.merge(df_total,df, how='left', on=[\"날짜\",max_key(df)])\n",
    "            if max_key_ != max_key(df):\n",
    "                df_total = df_total.drop([max_key_],axis=1)\n",
    "                df_total = pd.merge(df_total,df, how='left', on=\"날짜\")\n",
    "                \n",
    "        except:\n",
    "            error_list.append([key1,key2,key3,key4])\n",
    "    \n",
    "    if len(single_list) > 0 : #single_list에 total_max_key를 추가하는 이유는, total_max_key와 비교하기 위함\n",
    "        single_list.insert(0, max_key(df_total))\n",
    "    return max_key(df_total), single_list, error_list #single_list는 결측값이 있는 검색어 중 최대값일 가능성이 있는 단어추후 업데이트(개별로 one_search로 구해서 한달치에 곱하고 merge 하는게 좋아보임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_max_key, single_list, error_list = find_max_key(keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbf97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_max_key # 결측치가 없는 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa29fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947638f",
   "metadata": {},
   "source": [
    "### error_list 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919f8a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_list = sum(error_list, [])\n",
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_error_list(error_list, total_max_key, single_list):\n",
    "    final_error = []\n",
    "    for i in error_list:\n",
    "        try:\n",
    "            df = one_search([total_max_key, i])\n",
    "            # 결측치 있는 최대값후보 single_list에 넣기\n",
    "            if total_max_key != max_key(df):\n",
    "                if df[max_key(df)].isnull().any(): #결측값이 하나라도 있으면 max_key가 되면 안 된다.\n",
    "                    single_list.append(max_key(df))\n",
    "                else:\n",
    "                    total_max_key = max_key(df)\n",
    "        except:\n",
    "            final_error.append(i)\n",
    "    return total_max_key, single_list, final_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_max_key, single_list, final_error = find_error_list(error_list, total_max_key, single_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79cbb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ae155",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_error #검색량 검색결과 하루의 결과도 반환하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 없는 키워드              ######################################singlr_list 뒤로 안 가도 되나?\n",
    "keyword_list = [x for x in keyword_list if x not in final_error]\n",
    "keyword_list = [x.replace(' ','') for x in keyword_list] #공백제거(한달치 검색량에 안 잡힘)\n",
    "len(keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af16a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# 저장\n",
    "with open('data/input_keyword/total_keyword.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8f8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foodlist를 바꾸지 않았으면 여기부터!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "import csv\n",
    "keyword_list = []\n",
    "with open('data/input_keyword/total_keyword.csv','r',newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        keyword_list.append(row)\n",
    "keyword_list = sum(keyword_list, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d74064",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keyword_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9d189",
   "metadata": {},
   "source": [
    "### single_list 중 total_max_key보다 작을 수도 있는 값 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ef0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 있던 max_key()후보와 total_max_key를 다시 비교해서 최종 total_max_key보다 작은 값은 포함\n",
    "def find_unmax_key(keyword):\n",
    "    if len(keyword) == 0:\n",
    "        print(\"모든 검색어가 이미 포함되었습니다.\")\n",
    "        return []\n",
    "    \n",
    "    elif len(keyword) > 0:\n",
    "        single_list = []\n",
    "\n",
    "        # 검색어 리스트가 4의 배수가 아니면 4의 배수로 만들기 (검색오류 대비)\n",
    "        while (len(keyword)%4-1) != 0:\n",
    "            keyword.append('임시')\n",
    "\n",
    "        #한번 미리 실행\n",
    "        df = one_search(keyword[0])\n",
    "        df_total = df.copy()\n",
    "\n",
    "        # 검색어 리스트 값을 키워드로 지정\n",
    "        for i in range(1, len(keyword)-3, 4):\n",
    "            key1 = keyword[i]\n",
    "            key2 = keyword[i+1]\n",
    "            key3 = keyword[i+2]\n",
    "            key4 = keyword[i+3]\n",
    "\n",
    "            # 데이터 프레임 정의\n",
    "            keyword_group_set = {\n",
    "                'keyword_group_1': {'groupName': keyword[0], 'keywords': [keyword[0]]},\n",
    "                'keyword_group_2': {'groupName': key1, 'keywords': [key1]},\n",
    "                'keyword_group_3': {'groupName': key2, 'keywords': [key2]},\n",
    "                'keyword_group_4': {'groupName': key3, 'keywords': [key3]},\n",
    "                'keyword_group_5': {'groupName': key4, 'keywords': [key4]}\n",
    "            }\n",
    "\n",
    "            naver = NaverDataLabOpenAPI()\n",
    "\n",
    "            naver.add_keyword_groups(keyword_group_set['keyword_group_1'])\n",
    "            naver.add_keyword_groups(keyword_group_set['keyword_group_2'])\n",
    "            naver.add_keyword_groups(keyword_group_set['keyword_group_3'])\n",
    "            naver.add_keyword_groups(keyword_group_set['keyword_group_4'])\n",
    "            naver.add_keyword_groups(keyword_group_set['keyword_group_5'])\n",
    "            df = naver.get_data()\n",
    "\n",
    "            if keyword[0] != max_key(df):\n",
    "                for i in [key1,key2,key3,key4]:\n",
    "                    df_ = df.iloc[:,1:]\n",
    "                    if df_[keyword[0]].max() < df_[i].max():\n",
    "                           single_list.append(i)\n",
    "        print('정상적으로 처리되었습니다.')                  \n",
    "        return single_list #single_list는 결측값이 있는 검색어 중 최대값일 가능성이 있는 단어추후 업데이트(개별로 one_search로 구해서 한달치에 곱하고 merge 하는게 좋아보임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 제거값\n",
    "single_list = find_unmax_key(single_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36242a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713c628",
   "metadata": {},
   "source": [
    "# 검색량 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_unique = []\n",
    "for v in keyword_list:\n",
    "    if v not in keyword_unique:\n",
    "        keyword_unique.append(v)\n",
    "keyword = keyword_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ce8ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def search_amount(keyword):\n",
    "    keyword = [x for x in keyword if x not in single_list] #single_list 검색어는 제외. 추후 실제값으로 합칠 예정\n",
    "    keyword = [x.replace(' ','') for x in keyword]\n",
    "    # 리스트에 중복값 있을 경우 삭제 (시간복잡도가 늘어나더라도 순서가 바뀌지 않도록 for문 사용)\n",
    "    keyword_unique = []\n",
    "    for v in keyword:\n",
    "        if v not in keyword_unique:\n",
    "            keyword_unique.append(v)\n",
    "    keyword = keyword_unique.copy()\n",
    "\n",
    "    # find_max_key를 맨 앞으로 (나중에 완성되면 total_max_key를 max_key(keyword) 로)\n",
    "    keyword.remove(total_max_key)\n",
    "    keyword.insert(0,total_max_key)\n",
    "\n",
    "    # 검색어 리스트가 4의 배수가 아니면 4의 배수로 만들기 (검색오류 대비)\n",
    "    while (len(keyword)%4-1) != 0:\n",
    "        keyword.append('임시')\n",
    "\n",
    "    #한번 미리 실행\n",
    "    naver = NaverDataLabOpenAPI()\n",
    "    naver.add_keyword_groups({'groupName': keyword[0], 'keywords': [keyword[0]]})\n",
    "    df = naver.get_data()\n",
    "    df_total = df.copy()\n",
    "\n",
    "\n",
    "    # 검색어 리스트 값을 키워드로 지정\n",
    "    for i in tqdm(range(1, len(keyword)-3, 4)):\n",
    "        key1 = keyword[i]\n",
    "        key2 = keyword[i+1]\n",
    "        key3 = keyword[i+2]\n",
    "        key4 = keyword[i+3]\n",
    "\n",
    "        # 데이터 프레임 정의\n",
    "        keyword_group_set = {\n",
    "            'keyword_group_1': {'groupName': keyword[0], 'keywords': [keyword[0]]},\n",
    "            'keyword_group_2': {'groupName': key1, 'keywords': [key1]},\n",
    "            'keyword_group_3': {'groupName': key2, 'keywords': [key2]},\n",
    "            'keyword_group_4': {'groupName': key3, 'keywords': [key3]},\n",
    "            'keyword_group_5': {'groupName': key4, 'keywords': [key4]}\n",
    "        }\n",
    "\n",
    "\n",
    "        naver = NaverDataLabOpenAPI()\n",
    "\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_1'])\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_2'])\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_3'])\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_4'])\n",
    "        naver.add_keyword_groups(keyword_group_set['keyword_group_5'])\n",
    "        df = naver.get_data()\n",
    "        \n",
    "        df_total = pd.merge(df_total,df, how='left', on=[\"날짜\",keyword[0]])\n",
    "\n",
    "    #중복값/4의 배수를 만들기 위해 생성한 값 삭제\n",
    "    if keyword[-1] == '임시':\n",
    "        #df_total = df_total.T.drop_duplicates().T\n",
    "        df_total = df_total[df_total.columns.drop(list(df_total.filter(regex='임시')))]\n",
    "        #df.drop(df[df.columns[pd.Series(df.columns).str.startswith('임시')]], axis=1)\n",
    "    \n",
    "    #원래 리스트 순서대로 정렬\n",
    "    keyword_unique.insert(0, '날짜')\n",
    "    df = df_total[keyword_unique]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767054d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = search_amount(keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = str(datetime.now().date().strftime('%Y%m%d'))\n",
    "df.to_csv(f'data/result/search_result{date}.csv', index=False)\n",
    "df = pd.read_csv(f'data/result/search_result{date}.csv')\n",
    "#df = pd.read_csv('data/news/search_result_naver500_20221116.csv')\n",
    "df['날짜'] = df['날짜'].astype('datetime64[ns]')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null이 없는 검색어만 출력\n",
    "df[df.columns[df.isna().sum() == 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bdabee",
   "metadata": {},
   "source": [
    "# 특정 검색어의 한달치 실제 검색량 구하기\n",
    "- https://www.sagein.net/m/652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from powernad.API.Campaign import *\n",
    "from powernad.API.RelKwdStat import *\n",
    "from time import sleep\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19731f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어의 최근 한달 검색량 반환\n",
    "def search_keyword(searchword):\n",
    "    rel = RelKwdStat(Parameter.BASE_URL, Parameter.API_KEY, Parameter.SECRET_KEY, Parameter.CUSTOMER_ID)\n",
    "    kwdDataList = rel.get_rel_kwd_stat_list(siteId=None, biztpId=None, hintKeywords=searchword, event=None, month=None, showDetail='1')\n",
    "    kwd_result = (kwdDataList[0].relKeyword, #키워드\n",
    "                 kwdDataList[0].monthlyPcQcCnt, #월간 검색수 (PC)-최근30일\n",
    "                 kwdDataList[0].monthlyMobileQcCnt, # 월간 검색수 (Mobile)-최근30일\n",
    "                 kwdDataList[0].monthlyPcQcCnt+kwdDataList[0].monthlyMobileQcCnt) # 월간 total \n",
    "\n",
    "    return(kwd_result[3])\n",
    "    #[outdata.relKeyword for outdata in kwdDataList] ---> 연관검색어\n",
    "    #return kwd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf1804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 식품안전나라 최근 1달 검색 절대값\n",
    "search_keyword('식품안전나라')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 식품안전나라 최근 1달 상대값 합계\n",
    "df['식품안전나라'].tail(30).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962dd757",
   "metadata": {},
   "source": [
    "# 실제값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4453419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_amount(keyword):\n",
    "    #결측값이 있는 검색어가 포함되지 않도록(식품안전나라와 같이 결측값이 측정에 들어가면 오차 수치가 낮아짐. 예외처리 해줘야함)\n",
    "    keyword = [x.replace(' ','') for x in keyword]\n",
    "    sample_candidate = []\n",
    "    for i in df.columns: \n",
    "        if (df[i].isnull().any() == False):\n",
    "            sample_candidate.append(i)\n",
    "    keyword = [x for x in keyword if x not in single_list] #개별로 계산한 single_list로 계산하지 않도록\n",
    "    keyword = [x for x in keyword if x in sample_candidate]\n",
    "\n",
    "    #실제값 변환, 오차율,MSE를 구하기 위한 샘플\n",
    "    keyword_sample = random.sample(keyword, 5) #5개만으로 추출하지만, 예비용으로 10개 설정\n",
    "\n",
    "    #최근 한달이 이전30일을 제공하기 떄문에 -1month 가 아닌 -30days(오늘 제외)\n",
    "    start_date = str(datetime.now().date() - relativedelta(days=30)) #한달 전\n",
    "    end_date =  str(datetime.now().date() - relativedelta(days=1)) #어제\n",
    "\n",
    "    calculator_dict = {}\n",
    "    #last_month_index = int(df[df['날짜']==start_date].index.values)\n",
    "    month_amount_dict = {}\n",
    "    for i in keyword_sample:\n",
    "        last_month = df.tail(30)[i] #원래 인덱스로 읽어왔으나, 결측값이 있는 경우 인덱스가 줄어들기 때문에 tail(30)이 정확하다고 판단하여 수정\n",
    "        month_amount = search_keyword(i) # 검색어 하나의 한달 실제 검색량\n",
    "        month_amount_dict[i] = month_amount\n",
    "        calculator = month_amount / last_month.sum() # 100의 값(100값 x 비율(values) 하면 실제 값이 나옴)\n",
    "        calculator_dict[i] = calculator\n",
    "        sleep(0.3)\n",
    "\n",
    "    calculator = sum(calculator_dict.values()) / len(keyword_sample)\n",
    "    result = df.iloc[:,1:] * calculator\n",
    "    final_df = pd.concat([df['날짜'], result], axis=1)\n",
    "\n",
    "    #성능평가(오차율, MSE). 오차를 측정할 경우 일일 호출량이 더 사용된다.\n",
    "    print(\"5개의 샘플을 추출하여 오차율과 MSE를 계산 중 입니다...\")\n",
    "    error_per_list = []\n",
    "    MSE_list =[]\n",
    "    for i in calculator_dict.items():\n",
    "        temp_df = one_search(i[0])\n",
    "        real_amount_month = month_amount_dict[i[0]] / temp_df[i[0]].tail(30).sum()\n",
    "        real_amount_df = real_amount_month * temp_df[i[0]].tail(30)\n",
    "        error_per = (abs(real_amount_df.mean() - result.tail(30)[i[0]].mean())*100/real_amount_df.mean())\n",
    "        MSE = np.square(real_amount_df.mean() - result.tail(30)[i[0]].mean()).sum()/len(result)\n",
    "        error_per_list.append(error_per)\n",
    "        MSE_list.append(MSE)        \n",
    "        print(f\"검색어 '{i[0]}'에 대한 오차율: {error_per}, MSE: {MSE}\")\n",
    "        \n",
    "    #오차율 기준(10%)을 넘는 샘플이 있으면 다시 샘플 추출\n",
    "    if (len(keyword) >= 50) and (sorted(error_per_list, reverse=True)[0] >= 10): #리스트 내 검색어 수가 50개가 넘을 시에만 실행\n",
    "        print('오차율 10% 넘는 샘플이 발견되어 샘플을 다시 추출합니다..')\n",
    "        real_amount(keyword) #재귀함수\n",
    "\n",
    "    #결측값이 있으면서 total_max_key보다 큰 값은 따로 concat (이상치여도 어쩔 수 없음)\n",
    "    if len(single_list) > 0:\n",
    "        for i in single_list:\n",
    "            single_df = one_search([total_max_key,i])\n",
    "            single_amount = search_keyword(i) / single_df[i].tail(30).sum()\n",
    "            single_amount_df = single_amount * single_df[i]\n",
    "            final_df = pd.concat([final_df, single_amount_df], axis=1, sort=True)\n",
    "    return final_df, np.mean(error_per_list), np.mean(MSE_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da66df4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_df, error_per_average, MSE_average = real_amount(keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7508c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 오차율(5개 샘플 평균)\n",
    "error_per_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fda09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 평균제곱오차(5개 샘플 평균)\n",
    "MSE_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e74dd4",
   "metadata": {},
   "source": [
    "# 시각화\n",
    "- 아래는 발전 가능성?\n",
    "- https://cordingdiary.tistory.com/109\n",
    "- https://www.analyticsvidhya.com/blog/2021/12/anomaly-detection-model-using-facebook-prophet/\n",
    "- https://predictor-ver1.tistory.com/4\n",
    "- https://zzsza.github.io/data/2019/02/06/prophet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 그래프 작성을 위해 값이 2개 최소 이상인 검색어만 추출\n",
    "df_ = final_df[final_df.columns[final_df.isnull().sum() < len(final_df)-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e7b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_1 = plot_monthly_trend(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08ca15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_2 = plot_daily_trend(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0dc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAN값이 많은 데이터는 예측이 떨어짐. 값이 1개밖에 없는 경우 오류발생\n",
    "fig_3 = plot_pred_trend(df_, days = 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea49b0",
   "metadata": {},
   "source": [
    "# 상관관계 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값이 없는 열만 시각화 (식품안전나라도 제외되므로 포함시 유의)\n",
    "sample_candidate = []\n",
    "for i in df_.columns:\n",
    "    if (df_[i].isnull().any() == False):\n",
    "        sample_candidate.append(i)\n",
    "keyword = keyword_list.copy()\n",
    "#keyword = [x for x in keyword if x not in single_list]\n",
    "keyword = [x for x in keyword if x in sample_candidate]\n",
    "\n",
    "df__ = df_[keyword]\n",
    "df__ = df__[final_df['날짜'] >= '2016-01-01'].reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20494503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df__.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c381244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림 사이즈 지정\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# 삼각형 마스크를 만든다(위 쪽 삼각형에 True, 아래 삼각형에 False)\n",
    "mask = np.zeros_like(df__.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# 히트맵을 그린다\n",
    "sns.heatmap(df__.corr(), \n",
    "            cmap = 'RdYlBu_r', \n",
    "            annot = True,   # 실제 값을 표시한다\n",
    "            mask=mask,      # 표시하지 않을 마스크 부분을 지정한다\n",
    "            linewidths=.5,  # 경계면 실선으로 구분하기\n",
    "            cbar_kws={\"shrink\": .5},# 컬러바 크기 절반으로 줄이기\n",
    "            vmin = -1,vmax = 1   # 컬러바 범위 -1 ~ 1\n",
    "           )  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02b518",
   "metadata": {},
   "source": [
    "# 정규화해서 곱해 실제값을 구하는 방법(호출량 절약)\n",
    "- https://foss4g.tistory.com/1410"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b93ddc",
   "metadata": {},
   "source": [
    "# 연령대별 검색량(실제값 변환은 어려움)\n",
    "- https://yenpa.tistory.com/m/10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65bb82",
   "metadata": {},
   "source": [
    "# 연관검색어\n",
    "- https://yenpa.tistory.com/m/20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1dbd4f",
   "metadata": {},
   "source": [
    "# 거리계산(군집 나누기)\n",
    "\n",
    "df_ = result_df.max().drop('날짜')\n",
    "\n",
    "from scipy.spatial import distance\n",
    "print(distance.euclidean(df_['포도'], df_['사과']))\n",
    "print(distance.cityblock(df_['포도'], df_['사과']))\n",
    "print(distance.hamming(df_['포도'], df_['사과']))\n",
    "\n",
    "df.max() - df.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
